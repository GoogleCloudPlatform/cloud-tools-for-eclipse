could.not.retrieve.buckets.for.project=Could not retrieve buckets for project {0}
account=&Account:
artifact.id=&Artifact ID:
RUN_OPTIONS=Dataflow Default Run Options
set.run.options=Set Default Cloud Dataflow Run Options
DATAFLOW_PIPELINE_OPTIONS=Set default options for running a Dataflow Pipeline.
execution.options.for.google.cloud.platform=Execution Options for Google Cloud Platform
CREATE_DATAFLOW_PROJECT=Create a Cloud Dataflow Project
wizard.description=This wizard creates a new Google Cloud Dataflow project.
GROUP_ID_TOOLTIP=The Maven Group ID. Should Be an Alphanumeric Path Separated by Periods
ARTIFACT_ID_TOOLTIP=The Maven Artifact ID. Should Be an Alphanumeric Name Separated by Dashes
browse=&Browse
cloud.platform.project.id=Cloud Platform &Project ID:
cloud.storage.staging.location=Cloud Storage Staging &Location:
could.not.create.staging.location=Could not create staging location at {0}
couldnt.fetch.bucket=Couldn''t fetch bucket {0}.
create.bucket=&Create Bucket
created.staging.location.at=Created staging location at {0}
dataflow.version=Dataflow &version:
UNSET_PACKAGE_TOOLTIP=If Unset This Will Be the Same as the Group ID
location.tooltip=An Existing Local Directory where the Project Will Be Created
missing.required.property=Missing required property {0}
name.template=Name &template:
name.template.tooltip=Optional Eclipse Project Name Template such as [groupId]-[artifactId].
new.cloud.dataflow.project=New Cloud Dataflow Project
runner=Runner:
package=&Package:
pipeline.arguments=Pipeline Arguments
pipeline.options=Pipeline Options:
project.template=Project &template:
SELECT_PROJECT_LOCATION=Select project location
set.pipeline.run.option.defaults=Set Pipeline Run Option Defaults
sign.into.another.account=Sign into another account...
verified.bucket.is.accessible=Verified bucket {0} is accessible.
search=&Search...
update.hierarchy=Update Hierarchy
use.default.workspace.location=Use default &workspace location
example.group.id=com.company.product
group.id=&Group ID:
location=&Location:
